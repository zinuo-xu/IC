import h5py
import os
import numpy as np
import scipy.io
from scipy import stats
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import ndimage # é¢„å¤„ç†éœ€è¦ç”¨åˆ°
import time # å¯¼å…¥ time æ¨¡å—ç”¨äºè®¡æ—¶

# %% å®šä¹‰é…ç½®

class ExpConfig:
    def __init__(self, file_path = None):
        # åŠ è½½é…ç½®æ–‡ä»¶
        if file_path is not None:
            try:
                self.load_config(file_path)
            except Exception as e:
                print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
                self.set_default_config()
        else:
            self.set_default_config()
        self.preprocess_cfg = {
            'preprocess': True,
            'win_size' : 150
        }

    def load_config(self, file_path):
        # ä»æ–‡ä»¶åŠ è½½é…ç½®
        if not file_path.endswith('.json'):
            raise NotImplementedError("ç›®å‰ä»…æ”¯æŒJSONæ ¼å¼çš„é…ç½®æ–‡ä»¶")
        # è§£æé…ç½®æ•°æ®
        import json
        with open(file_path, 'r') as f:
            config_data = json.load(f)  

        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_keys = ['DATA_PATH']
        missing = [k for k in required_keys if k not in config_data]
        if missing:
            raise KeyError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å­—æ®µ: {', '.join(missing)}")
        
        # èµ‹å€¼é…ç½®
        self.data_path = config_data.get("DATA_PATH")
        self.trial_info = config_data.get("TRIAL_INFO", {})
        self.exp_info = config_data.get("EXP_INFO")


    def set_default_config(self):
        # è®¾ç½®é»˜è®¤é…ç½®
        # æ•°æ®è·¯å¾„
        self.data_path = r'C:\Users\xuzinuo\Desktop\79'
        # è¯•æ¬¡ä¿¡æ¯
        self.trial_info = {
            "TRIAL_START_SKIP": 0,
            "TOTAL_TRIALS": 180
        }
        # åˆºæ¿€å‚æ•°
        self.exp_info = {
            "t_stimulus": 12,  #åˆºæ¿€å‰å¸§æ•°
            "l_stimulus": 8,   #åˆºæ¿€æŒç»­å¸§æ•°
            "l_trials": 32,    #å•è¯•æ¬¡æ€»å¸§æ•°
            "IPD":2.0,
            "ISI":6.0
        }


cfg = ExpConfig(r'C:\Users\xuzinuo\Desktop\79\M79.json')

# %% é¢„å¤„ç†ç›¸å…³å‡½æ•°å®šä¹‰(é€šç”¨)
# ä»matlabæ”¹è¿‡æ¥çš„ï¼Œç»è¿‡æ£€æŸ¥åº”è¯¥æ— è¯¯
def process_trigger(txt_file, IPD=cfg.exp_info["IPD"], ISI=cfg.exp_info["ISI"], fre=None, min_sti_gap=4.0):
    """
    å¤„ç†è§¦å‘æ–‡ä»¶ï¼Œä¿®æ”¹è‡ªstep1x_trigger_725right.m
    """
    
    # è¯»å…¥æ–‡ä»¶
    data = []
    with open(txt_file, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 2:
                try:
                    time_val = float(parts[0])
                    ch_str = parts[1]
                    abs_ts = float(parts[2]) if len(parts) >= 3 else None
                    data.append((time_val, ch_str, abs_ts))
                except ValueError:
                    continue
    
    if not data:
        raise ValueError("æœªèƒ½ä»æ–‡ä»¶ä¸­è¯»å–åˆ°æœ‰æ•ˆæ•°æ®")
    
    # è§£ææ•°æ®
    times, channels, abs_timestamps = zip(*data)
    times = np.array(times)
    
    # è½¬æ¢é€šé“ä¸ºæ•°å€¼ï¼Œéæ•°å€¼çš„è®¾ä¸ºNaN
    ch_numeric = []
    valid_indices = []
    for i, ch_str in enumerate(channels):
        try:
            ch_val = float(ch_str)
            ch_numeric.append(ch_val)
            valid_indices.append(i)
        except ValueError:
            continue
    
    if not valid_indices:
        raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°å€¼é€šé“æ•°æ®")
    
    # åªä¿ç•™æœ‰æ•ˆæ•°æ®
    t = times[valid_indices]
    ch = np.array(ch_numeric)
    
    # ç›¸æœºå¸§ä¸åˆºæ¿€èµ·å§‹æ—¶é—´
    cam_t_raw = t[ch == 1]
    sti_t_raw = t[ch == 2]
    
    if len(cam_t_raw) == 0:
        raise ValueError("æœªæ£€æµ‹åˆ°ç›¸æœºè§¦å‘(å€¼=1)")
    if len(sti_t_raw) == 0:
        raise ValueError("æœªæ£€æµ‹åˆ°åˆºæ¿€è§¦å‘(å€¼=2)")
    
    # å»é‡/åˆå¹¶ï¼šå°†æ—¶é—´é å¾—å¾ˆè¿‘çš„"2"è§†ä½œåŒä¸€æ¬¡åˆºæ¿€
    sti_t = np.sort(sti_t_raw)
    if len(sti_t) > 0:
        keep = np.ones(len(sti_t), dtype=bool)
        for i in range(1, len(sti_t)):
            if (sti_t[i] - sti_t[i-1]) < min_sti_gap:
                keep[i] = False  # åˆå¹¶åˆ°å‰ä¸€ä¸ª
        sti_t = sti_t[keep]
    
    # å¸§ç‡ä¼°è®¡æˆ–ä½¿ç”¨ç»™å®šå€¼
    if fre is None:
        dt = np.diff(cam_t_raw)
        fre = 1 / np.median(dt)  # ç”¨ç›¸æœºå¸§æ—¶é—´æˆ³çš„ä¸­ä½é—´éš”

    IPD_frames = max(1, round(IPD * fre))
    isi_frames = round((IPD + ISI) * fre)
    
    # æŠŠæ¯ä¸ªåˆºæ¿€æ—¶é—´æ˜ å°„åˆ°æœ€è¿‘çš„ç›¸æœºå¸§ç´¢å¼•
    cam_t = cam_t_raw.copy()
    nFrames = len(cam_t)
    start_edge = np.zeros(len(sti_t), dtype=int)        #æ‰€æœ‰åˆºæ¿€èµ·å§‹å¸§
    
    for k in range(len(sti_t)):
        idx = np.argmin(np.abs(cam_t - sti_t[k]))
        start_edge[k] = idx
    
    end_edge = start_edge + IPD_frames - 1
    
    # è¾¹ç•Œè£å‰ªï¼Œé¿å…è¶Šç•Œ
    valid = (start_edge >= 0) & (end_edge < nFrames) & (start_edge <= end_edge)
    start_edge = start_edge[valid]
    end_edge = end_edge[valid]
    
    # å°¾æ®µå®Œæ•´æ€§æ£€æŸ¥ï¼ˆä¸æ—§é€»è¾‘ä¸€è‡´ï¼‰
    if len(start_edge) >= 2:
        d = np.diff(start_edge)
        while len(d) > 0 and d[-1] not in [isi_frames-1, isi_frames, isi_frames+1, isi_frames+2]:
            # ä¸¢æ‰æœ€åä¸€ä¸ªå¯ç–‘çš„åˆºæ¿€æ®µ
            start_edge = start_edge[:-1]
            end_edge = end_edge[:-1]
            if len(start_edge) >= 2:
                d = np.diff(start_edge)
            else:
                break
    
    # ç”Ÿæˆ0/1åˆºæ¿€æ•°ç»„ï¼ˆå¯è§†åŒ–/ä¿å­˜ç”¨ï¼‰
    stimuli_array = np.zeros(nFrames)
    for i in range(len(start_edge)):
        stimuli_array[start_edge[i]:end_edge[i]+1] = 1
    
    # ä¿å­˜ç»“æœåˆ°matæ–‡ä»¶
    save_path = os.path.join(os.path.dirname(txt_file), 'visual_stimuli_with_label.mat')
    scipy.io.savemat(save_path, {
        'start_edge': start_edge,
        'end_edge': end_edge,
        'stimuli_array': stimuli_array
    })
    
    return {
        'start_edge': start_edge,
        'end_edge': end_edge,
        'stimuli_array': stimuli_array,
        'camera_frames': len(cam_t),
        'stimuli_count': len(start_edge)
    }

# ========== æ ¸å¿ƒä¿®æ”¹: å•ç±»åˆ«RRç¥ç»å…ƒç­›é€‰å‡½æ•° (åŸ rr_selection) ========== 
def _rr_selection_single(trials, t_stimulus=cfg.exp_info["t_stimulus"], l=cfg.exp_info["l_stimulus"], reliability_threshold=0.7, snr_threshold=0.8, effect_size_threshold=0.5, response_ratio_threshold=0.6, class_label="All"):
    """                                                                                                                                                                                                                                                                                                                                                                       
    å¯¹ä¸€ç»„è¯•æ¬¡ï¼ˆæ¥è‡ªä¸€ä¸ªåˆºæ¿€ç±»åˆ«ï¼‰è¿›è¡Œå¿«é€ŸRRç¥ç»å…ƒç­›é€‰
    """
    n_trials, n_neurons, n_timepoints = trials.shape
    
    print(f"æ­£åœ¨å¯¹ç±»åˆ« {class_label} è¿›è¡Œç­›é€‰, è¯•æ¬¡æ•°é‡: {n_trials}, ç¥ç»å…ƒæ•°é‡: {n_neurons}")
    
    # å®šä¹‰æ—¶é—´çª—å£
    baseline_pre = np.arange(0, t_stimulus)
    baseline_post = np.arange(t_stimulus + l, n_timepoints)
    stimulus_window = np.arange(t_stimulus, t_stimulus + l)
    
    # 1. å“åº”æ€§æ£€æµ‹ - å‘é‡åŒ–è®¡ç®—
    # è®¡ç®—åŸºçº¿å’Œåˆºæ¿€æœŸçš„å¹³å‡å€¼
    baseline_pre_mean = np.mean(trials[:, :, baseline_pre], axis=2)  # (trials, neurons)
    baseline_post_mean = np.mean(trials[:, :, baseline_post], axis=2)  # (trials, neurons)
    # åˆå¹¶å‰ååŸºçº¿çš„å¹³å‡
    baseline_mean = (baseline_pre_mean + baseline_post_mean) / 2
    
    stimulus_mean = np.mean(trials[:, :, stimulus_window], axis=2)  # (trials, neurons)
    
    # ç®€åŒ–çš„å“åº”æ€§æ£€æµ‹ï¼šåŸºäºæ•ˆåº”å¤§å°å’Œæ ‡å‡†è¯¯å·®
    baseline_pre_std = np.std(trials[:, :, baseline_pre], axis=2)  # (trials, neurons)
    baseline_post_std = np.std(trials[:, :, baseline_post], axis=2)  # (trials, neurons)
    # åˆå¹¶å‰ååŸºçº¿çš„æ ‡å‡†å·®
    baseline_std = (baseline_pre_std + baseline_post_std) / 2
    
    stimulus_std = np.std(trials[:, :, stimulus_window], axis=2)
    
    # Cohen's dæ•ˆåº”å¤§å°
    pooled_std = np.sqrt((baseline_std**2 + stimulus_std**2) / 2)
    effect_size = np.abs(stimulus_mean - baseline_mean) / (pooled_std + 1e-8)
    
    # å“åº”æ€§æ ‡å‡†ï¼šå¹³å‡æ•ˆåº”å¤§å° > é˜ˆå€¼ ä¸” è‡³å°‘æŒ‡å®šæ¯”ä¾‹è¯•æ¬¡æœ‰å“åº”
    response_ratio = np.mean(effect_size > effect_size_threshold, axis=0)
    
    # å…´å¥‹æ€§å“åº” (Excitatory): å“åº”æ¯”ä¾‹ > é˜ˆå€¼ ä¸” å¹³å‡å“åº” > å¹³å‡åŸºçº¿æ¯”ä¾‹ > é˜ˆå€¼
    enhanced_neurons = np.where((response_ratio > response_ratio_threshold) & 
                                (np.mean(stimulus_mean > baseline_mean, axis=0) > response_ratio_threshold))[0].tolist()
    # æŠ‘åˆ¶æ€§å“åº” (Inhibitory): å“åº”æ¯”ä¾‹ > é˜ˆå€¼ ä¸” å¹³å‡å“åº” < å¹³å‡åŸºçº¿æ¯”ä¾‹ > é˜ˆå€¼
    inhibitory_neurons = np.where((response_ratio > response_ratio_threshold) &
                                  (np.mean(stimulus_mean < baseline_mean, axis=0) > response_ratio_threshold))[0].tolist()

    # 2. å¯é æ€§æ£€æµ‹ - ç®€åŒ–ç‰ˆæœ¬
    # è®¡ç®—æ¯ä¸ªç¥ç»å…ƒåœ¨æ¯ä¸ªè¯•æ¬¡çš„ä¿¡å™ªæ¯”
    signal_strength = np.abs(stimulus_mean - baseline_mean)
    noise_level = baseline_std + 1e-8
    snr = signal_strength / noise_level
    
    # å¯é æ€§ï¼šæŒ‡å®šæ¯”ä¾‹çš„è¯•æ¬¡ä¿¡å™ªæ¯” > é˜ˆå€¼
    reliability_ratio = np.mean(snr > snr_threshold, axis=0)
    reliable_neurons = np.where(reliability_ratio >= reliability_threshold)[0].tolist()
    
    # 3. æœ€ç»ˆRRç¥ç»å…ƒ
    rr_enhanced_neurons = list(set(enhanced_neurons) & set(reliable_neurons))
    rr_inhibitory_neurons = list(set(inhibitory_neurons) & set(reliable_neurons))
    
    print(f"ç±»åˆ« {class_label} ç­›é€‰ç»“æœ: å…´å¥‹æ€§RR: {len(rr_enhanced_neurons)}, æŠ‘åˆ¶æ€§RR: {len(rr_inhibitory_neurons)}")

    # è¿”å›ç¥ç»å…ƒåœ¨è¾“å…¥ trials ä¸­çš„**ç´¢å¼•**
    return set(rr_enhanced_neurons), set(rr_inhibitory_neurons)

# ========== æ–°å¢: åˆ†ç±»åˆ«RRç¥ç»å…ƒç­›é€‰å‡½æ•° (æ»¡è¶³ç”¨æˆ·éœ€æ±‚) ========== 
def rr_selection_by_class(segments, labels, **kwargs):
    """
    åˆ†åˆºæ¿€ç±»å‹ç­›é€‰ RR ç¥ç»å…ƒï¼Œç„¶åå–å¹¶é›†ã€‚
    
    å‚æ•°:
    segments: (n_trials, n_neurons, n_timepoints)
    labels: (n_trials,) åŒ…å«ç±»åˆ«æ ‡ç­¾çš„ NumPy æ•°ç»„
    **kwargs: ä¼ é€’ç»™ _rr_selection_single çš„ç­›é€‰å‚æ•°
    
    è¿”å›:
    rr_enhanced_neurons: å¯¹ä»»ä¸€åˆºæ¿€ç±»åˆ«æœ‰å…´å¥‹æ€§ RR çš„ç¥ç»å…ƒå…¨å±€ç´¢å¼• (åˆ—è¡¨)
    rr_inhibitory_neurons: å¯¹ä»»ä¸€åˆºæ¿€ç±»åˆ«æœ‰æŠ‘åˆ¶æ€§ RR çš„ç¥ç»å…ƒå…¨å±€ç´¢å¼• (åˆ—è¡¨)
    """
    start_time = time.time()
    print("\nå¼€å§‹åˆ†ç±»åˆ« RR ç¥ç»å…ƒç­›é€‰...")
    
    all_class_ids = sorted(np.unique(labels))
    # ç±»åˆ« 0 é€šå¸¸æ˜¯æ— æ•ˆ/è·³è¿‡çš„è¯•æ¬¡ï¼Œè·³è¿‡
    valid_class_ids = [cls for cls in all_class_ids if cls > 0]
    
    # åˆå§‹åŒ–å…¨å±€ RR ç¥ç»å…ƒé›†åˆï¼ˆå­˜å‚¨ç¥ç»å…ƒåœ¨ segments/labels ä¸­çš„**åˆ—ç´¢å¼•**ï¼‰
    global_rr_enhanced_set = set()
    global_rr_inhibitory_set = set()
    
    # å°† segments è½¬æ¢ä¸º (n_trials, n_neurons, n_timepoints)
    n_neurons = segments.shape[1]

    for class_id in valid_class_ids:
        # 1. ç­›é€‰å‡ºå½“å‰ç±»åˆ«çš„è¯•æ¬¡
        class_mask = (labels == class_id)
        class_segments = segments[class_mask, :, :]
        
        # æ£€æŸ¥è¯•æ¬¡æ•°é‡
        if class_segments.shape[0] < 2:
            print(f"è­¦å‘Š: ç±»åˆ« {class_id} è¯•æ¬¡æ•°é‡ä¸è¶³({class_segments.shape[0]})ï¼Œè·³è¿‡è¯¥ç±»åˆ«ç­›é€‰ã€‚")
            continue
            
        # 2. å¯¹å½“å‰ç±»åˆ«çš„è¯•æ¬¡è¿›è¡Œ RR ç­›é€‰
        # _rr_selection_single è¿”å›çš„æ˜¯**å½“å‰ class_segments** ä¸­çš„ç´¢å¼•
        rr_exc_local_indices, rr_inh_local_indices = _rr_selection_single(
            class_segments, 
            class_label=str(int(class_id)), 
            **kwargs
        )
        
        # 3. å°†ç»“æœï¼ˆå±€éƒ¨ç´¢å¼•ï¼‰åˆå¹¶åˆ°å…¨å±€é›†åˆä¸­
        # æ³¨æ„ï¼šç”±äºæˆ‘ä»¬æ˜¯å¯¹æ•´ä¸ª segments æ•°ç»„çš„å­é›†è¿›è¡Œæ“ä½œï¼Œ
        # _rr_selection_single è¿”å›çš„ç´¢å¼•æ˜¯é’ˆå¯¹ segments æ•°ç»„çš„**åˆ—ç´¢å¼•** (å³ç¥ç»å…ƒç´¢å¼•)ï¼Œ
        # å› æ­¤å¯ä»¥ç›´æ¥åˆå¹¶ï¼Œæ— éœ€æ˜ å°„ã€‚
        global_rr_enhanced_set.update(rr_exc_local_indices)
        global_rr_inhibitory_set.update(rr_inh_local_indices)

    # ç»“æœè½¬ä¸ºåˆ—è¡¨å¹¶æ’åº
    rr_enhanced_neurons = sorted(list(global_rr_enhanced_set))
    rr_inhibitory_neurons = sorted(list(global_rr_inhibitory_set))
    
    elapsed_time = time.time() - start_time
    print(f"\nåˆ†ç±»åˆ« RR ç­›é€‰å®Œæˆï¼Œæ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
    print(f"æœ€ç»ˆç­›é€‰ç»“æœ (å–å¹¶é›†): å…´å¥‹æ€§RRç¥ç»å…ƒæ€»æ•°: {len(rr_enhanced_neurons)}, æŠ‘åˆ¶æ€§RRç¥ç»å…ƒæ€»æ•°: {len(rr_inhibitory_neurons)}")
    
    # åŒæ—¶è¿”å›æ‰€æœ‰å¯é ç¥ç»å…ƒçš„é›†åˆï¼Œä»¥å¤‡ä¸æ—¶ä¹‹éœ€ï¼ˆä½†åŸé€»è¾‘ä¸­æœªä½¿ç”¨ï¼‰
    return rr_enhanced_neurons, rr_inhibitory_neurons


# ========== æ•°æ®åˆ†å‰²å‡½æ•° (ä¿æŒä¸å˜) ========== 
def segment_neuron_data(neuron_data, trigger_data, label, pre_frames=cfg.exp_info["t_stimulus"], post_frames=cfg.exp_info["l_trials"]-cfg.exp_info["t_stimulus"]):
    """
    æ”¹è¿›çš„æ•°æ®åˆ†å‰²å‡½æ•°
    """
    total_frames = pre_frames + post_frames
    # segment å½¢çŠ¶: (n_triggers, n_neurons, n_timepoints)
    segments = np.zeros((len(trigger_data), neuron_data.shape[1], total_frames))
    labels = []

    for i in range(len(trigger_data)): # éå†æ¯ä¸ªè§¦å‘äº‹ä»¶
        start = trigger_data[i] - pre_frames
        end = trigger_data[i] + post_frames
        # è¾¹ç•Œæ£€æŸ¥
        if start < 0 or end >= neuron_data.shape[0]:
            print(f"è­¦å‘Š: ç¬¬{i}ä¸ªåˆºæ¿€çš„æ—¶é—´çª—å£è¶…å‡ºè¾¹ç•Œï¼Œè·³è¿‡")
            continue
        segment = neuron_data[start:end, :]
        segments[i] = segment.T
        labels.append(label[i])
    labels = np.array(labels)
    return segments, labels

# =================================================================
# %% ç¼“å­˜å‡½æ•° (ä¿æŒä¸å˜)
# =================================================================
def save_preprocessed_data_npz(segments, labels, neuron_pos_filtered, file_path):
    """ä¿å­˜é¢„å¤„ç†ä¸­é—´æ•°æ® (segments, labels, filtered_neuron_pos) åˆ° .npz æ–‡ä»¶ã€‚"""
    try:
        np.savez_compressed(
            file_path, 
            segments=segments, 
            labels=labels, 
            neuron_pos_filtered=neuron_pos_filtered
        )
        print(f"å·²å°†é¢„å¤„ç†ä¸­é—´æ•°æ®ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶: {file_path}")
    except Exception as e:
        print(f"ä¿å­˜é¢„å¤„ç†æ•°æ®å¤±è´¥: {e}")

def load_preprocessed_data_npz(file_path):
    """ä» .npz æ–‡ä»¶åŠ è½½é¢„å¤„ç†ä¸­é—´æ•°æ®ã€‚"""
    try:
        # allow_pickle=True æ˜¯ä¸ºäº†å…¼å®¹æ—§ç‰ˆ numpy æ•°ç»„ï¼Œä½†è¿™é‡Œä¸»è¦ç”¨äºåŠ è½½å¤šä¸ªæ•°ç»„
        data = np.load(file_path, allow_pickle=True)
        print(f"å°è¯•ä»ç¼“å­˜æ–‡ä»¶åŠ è½½é¢„å¤„ç†ä¸­é—´æ•°æ®: {file_path}")
        return data['segments'], data['labels'], data['neuron_pos_filtered']
    except Exception as e:
        print(f"åŠ è½½é¢„å¤„ç†æ•°æ®å¤±è´¥: {e}")
        return None, None, None

# %% å®é™…åŠŸèƒ½å‡½æ•°
# ========== åŠ è½½æ•°æ® (ä¿æŒä¸å˜) ==============================
def load_data(data_path = cfg.data_path, start_idx=cfg.trial_info["TRIAL_START_SKIP"], end_idx=cfg.trial_info["TRIAL_START_SKIP"] + cfg.trial_info["TOTAL_TRIALS"]):
    '''
    åŠ è½½ç¥ç»æ•°æ®ã€ä½ç½®æ•°æ®ã€è§¦å‘æ•°æ®å’Œåˆºæ¿€æ•°æ®
    '''
    ######### è¯»å–ç¥ç»æ•°æ® #########
    print("å¼€å§‹å¤„ç†æ•°æ®...")
    mat_file = os.path.join(data_path, 'wholebrain_output.mat')
    if not os.path.exists(mat_file):
        raise ValueError(f"æœªæ‰¾åˆ°ç¥ç»æ•°æ®æ–‡ä»¶: {mat_file}")
    try:
        data = h5py.File(mat_file, 'r')
    except Exception as e:
        raise ValueError(f"æ— æ³•è¯»å–matæ–‡ä»¶: {mat_file}ï¼Œé”™è¯¯ä¿¡æ¯: {e}")

    # æ£€æŸ¥å…³é”®æ•°æ®é›†æ˜¯å¦å­˜åœ¨
    if 'whole_trace_ori' not in data or 'whole_center' not in data:
        raise ValueError("matæ–‡ä»¶ç¼ºå°‘å¿…è¦çš„æ•°æ®é›†ï¼ˆ'whole_trace_ori' æˆ– 'whole_center'ï¼‰")

    # ==========ç¥ç»æ•°æ®================
    neuron_data = data['whole_trace_ori']
    # è½¬åŒ–æˆnumpyæ•°ç»„
    neuron_data = np.array(neuron_data)
    print(f"åŸå§‹ç¥ç»æ•°æ®å½¢çŠ¶: {neuron_data.shape}")
    
    # åªåšåŸºæœ¬çš„æ•°æ®æ¸…ç†ï¼šç§»é™¤NaNå’ŒInf
    neuron_data = np.nan_to_num(neuron_data, nan=0.0, posinf=0.0, neginf=0.0)
    neuron_pos = data['whole_center']
    # æ£€æŸ¥å’Œå¤„ç†neuron_posç»´åº¦
    if len(neuron_pos.shape) != 2:
        raise ValueError(f"neuron_pos åº”ä¸º2Dæ•°ç»„ï¼Œå®é™…ä¸º: {neuron_pos.shape}")
    
    # çµæ´»å¤„ç†ä¸åŒç»´åº¦çš„neuron_pos
    if neuron_pos.shape[0] > 2:
        # æ ‡å‡†æ ¼å¼ (4, n)ï¼Œæå–å‰ä¸¤ç»´
        neuron_pos = neuron_pos[0:2, :]
    elif neuron_pos.shape[0] == 2:
        # å·²ç»æ˜¯2ç»´ï¼Œç›´æ¥ä½¿ç”¨
        print(f"æ£€æµ‹åˆ°2ç»´neuron_posæ ¼å¼: {neuron_pos.shape}")
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„neuron_posç»´åº¦: {neuron_pos.shape[0]}ï¼ŒæœŸæœ›ä¸º2ã€3æˆ–4ç»´")

    # è§¦å‘æ•°æ®
    trigger_files = sorted([os.path.join(data_path, f) for f in os.listdir(data_path) if f.endswith('.txt')])
    # è¿‡æ»¤å‡ºåç§°ä¸­åŒ…å« trigger çš„ txtï¼Œç¡®ä¿æˆ‘ä»¬è¯»å–æ­£ç¡®çš„è§¦å‘æ–‡ä»¶
    trigger_txt_candidates = [f for f in trigger_files if 'trigger' in os.path.basename(f).lower()]
    if not trigger_txt_candidates:
        raise FileNotFoundError(f"åœ¨ {data_path} ä¸­æœªæ‰¾åˆ°åŒ…å« 'trigger' å­—æ ·çš„è§¦å‘txtæ–‡ä»¶ã€‚")
    trigger_data = process_trigger(trigger_txt_candidates[0])
    
    # åˆºæ¿€æ•°æ®
    stimulus_files = [os.path.join(data_path, f) for f in os.listdir(data_path) if f.endswith('.csv')]
    if not stimulus_files:
          # æ£€æŸ¥ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ï¼Œå‘ç° stimuli_20251024_1108.txt åŒ…å«åˆºæ¿€åºåˆ—
          txt_stim_files = [os.path.join(data_path, f) for f in os.listdir(data_path) if f.endswith('.txt') and 'stimuli' in f]
          if not txt_stim_files:
              raise FileNotFoundError(f"åœ¨ {data_path} ä¸­æœªæ‰¾åˆ°åˆºæ¿€csv/txtæ–‡ä»¶ã€‚")
          # å‡è®¾åˆºæ¿€åºåˆ—åœ¨åä¸º 'stimuli_...' çš„ txt æ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬è¿›è¡Œè§£æ
          print("è­¦å‘Š: æœªæ‰¾åˆ°åˆºæ¿€ csv æ–‡ä»¶ï¼Œå°è¯•è§£æ stimuli_...txt æ–‡ä»¶ã€‚")
          # è¿™é‡Œéœ€è¦æ ¹æ® stimuli_20251024_1108.txt çš„æ ¼å¼è¿›è¡Œé¢å¤–è§£æ
          # ç”±äºåŸä»£ç é¢„æœŸæ˜¯ CSVï¼Œä¸”ç”¨æˆ·æä¾›çš„ stimuli_20251024_1108.txt æ˜¯ä¸€ä¸ªåŒ…å«åºåˆ—çš„æ–‡æœ¬ï¼Œ
          # æš‚æ—¶å‡è®¾åœ¨å®é™…è¿è¡Œç¯å¢ƒä¸­ä¼šæœ‰ä¸€ä¸ª CSV æ–‡ä»¶ï¼Œæˆ–è€…ç”¨æˆ·ä¼šä¿®æ”¹è¿™éƒ¨åˆ†é€»è¾‘ã€‚
          # é’ˆå¯¹æä¾›çš„æ–‡ä»¶ï¼Œè§£æå‡º 'å®é™…å‘ˆç°åºåˆ— (å·²å‘ˆç°)'
          try:
              with open(txt_stim_files[-1], 'r', encoding='utf-8') as f:
                  content = f.read()
          except UnicodeDecodeError:
              with open(txt_stim_files[-1], 'r', encoding='utf-8', errors='ignore') as f:
                  print("è­¦å‘Š: UTF-8 è§£ç å¤±è´¥ï¼Œå·²å¿½ç•¥éæ³•å­—èŠ‚ç»§ç»­è§£æ stimuli txtã€‚")
                  content = f.read()
          # ç®€å•çš„æ­£åˆ™/å­—ç¬¦ä¸²æŸ¥æ‰¾æ¥æå–åºåˆ—
          import re
          match = re.search(r"å®é™…å‘ˆç°åºåˆ— \(å·²å‘ˆç°\): \r?\n?(\[.*?\])", content, re.DOTALL)
          if match:
              stim_list_str = match.group(1).replace("'", "\"")
              import json
              stim_list = json.loads(stim_list_str)
              stimulus_data = np.array(stim_list)
          else:
              raise ValueError("æœªèƒ½ä» stimuli_...txt æ–‡ä»¶ä¸­è§£æå‡ºåˆºæ¿€åºåˆ—ã€‚")
              
    else:
        stimulus_df = pd.read_csv(stimulus_files[0], header=None)
        # å‡è®¾æ‚¨çš„ CSV åªæœ‰ä¸€åˆ—ï¼Œæˆ‘ä»¬å°†å…¶è½¬æ¢ä¸º NumPy å­—ç¬¦ä¸²æ•°ç»„
        stimulus_data = stimulus_df.iloc[:, 0].values.astype(str) # å–ç¬¬ä¸€åˆ—ï¼ˆç´¢å¼• 0ï¼‰å¹¶è½¬ä¸ºå­—ç¬¦ä¸²æ•°ç»„
    
    # ä¿æŒæŒ‡å®šè¯•éªŒæ•°ï¼Œå»æ‰é¦–å°¾ - å¯¹è§¦å‘æ•°æ®å’Œåˆºæ¿€æ•°æ®åŒæ—¶å¤„ç†
    start_edges = trigger_data['start_edge'][start_idx:end_idx]
    # ç¡®ä¿ stimulus_data å’Œ start_edges é•¿åº¦ä¸€è‡´
    if len(stimulus_data) < (end_idx - start_idx):
        print(f"è­¦å‘Š: åˆºæ¿€æ•°æ® ({len(stimulus_data)}ä¸ª) å°‘äºæœŸæœ›çš„è¯•æ¬¡æ•°é‡ ({end_idx - start_idx}ä¸ª)ã€‚")
        num_trials = min(len(stimulus_data), len(start_edges))
        start_edges = start_edges[:num_trials]
        stimulus_data = stimulus_data[:num_trials]
    else:
        stimulus_data = stimulus_data[start_idx:end_idx] # ä½¿ç”¨ start_idx:end_idx 
    
    # è¿”å›åŸå§‹æ•°æ®ï¼Œç”¨äºåç»­çš„æ˜‚è´µé¢„å¤„ç†æ­¥éª¤
    return neuron_data, neuron_pos, start_edges, stimulus_data 


# ========== é¢„å¤„ç†çš„è€—æ—¶éƒ¨åˆ†ï¼šå»é™¤è´Ÿå€¼ç¥ç»å…ƒ + çŸ«æ­£ + åˆ†å‰²trial (ä¿æŒä¸å˜) ==================
def filter_and_segment_data(neuron_data, neuron_pos, start_edge, stimulus_data, cfg=cfg):
    """æ‰§è¡Œè€—æ—¶çš„ç¥ç»å…ƒè¿‡æ»¤ã€dF/Fé¢„å¤„ç†å’Œæ•°æ®åˆ†å‰²æ­¥éª¤ã€‚"""

    # =========== ç¬¬ä¸€æ­¥ æå–ä»…æœ‰æ­£å€¼çš„ç¥ç»å…ƒ==================
    # å¸¦è´Ÿå€¼çš„ç¥ç»å…ƒç´¢å¼•
    mask = np.any(neuron_data <= 0, axis=0)  # æ¯åˆ—æ˜¯å¦å­˜åœ¨ <=0
    keep_idx = np.where(~mask)[0]

    # å¦‚æœ neuron_pos ä¸ neuron_data çš„åˆ—å¯¹é½ï¼Œåˆ™åŒæ­¥åˆ é™¤å¯¹åº”åˆ—
    if neuron_pos.shape[1] == neuron_data.shape[1]:
        neuron_data_filtered = neuron_data[:, keep_idx]
        neuron_pos_filtered = neuron_pos[:, keep_idx]
    else:
        # å¦‚æœé•¿åº¦ä¸åŒ¹é…ï¼Œç†è®ºä¸Šåº”è¯¥åœ¨ load_data é˜¶æ®µå°±æŠ¥é”™ï¼Œè¿™é‡Œä¿ç•™åŸå§‹é€»è¾‘
        raise ValueError(f"è­¦å‘Š: neuron_pos åˆ—æ•°({neuron_pos.shape[1]}) ä¸ neuron_data åˆ—æ•°({neuron_data.shape[1]}) ä¸åŒ¹é…ï¼Œæœªä¿®æ”¹ neuron_pos")
    
    # =========== ç¬¬äºŒæ­¥ é¢„å¤„ç† (dF/F) ===========================
    if cfg.preprocess_cfg["preprocess"]:
        win_size = cfg.preprocess_cfg["win_size"]
        if win_size % 2 == 0:
            win_size += 1
        T, N = neuron_data_filtered.shape
        F0_dynamic = np.zeros((T, N), dtype=float)
        for i in range(N):
            # ndimage.percentile_filter è¾“å‡ºæ¯å¸§çš„çª—å£ç™¾åˆ†ä½å€¼
            F0_dynamic[:, i] = ndimage.percentile_filter(neuron_data_filtered[:, i], percentile=8, size=win_size, mode='reflect')
        # è®¡ç®— dF/Fï¼ˆé€å¸§ï¼‰
        dff = (neuron_data_filtered - F0_dynamic) / F0_dynamic
    else:
        dff = neuron_data_filtered
        F0_dynamic = None

  

    # =========== ç¬¬ä¸‰æ­¥ åˆ†å‰²ç¥ç»æ•°æ® =====================================
    labels = reclassify(stimulus_data)
    segments, labels = segment_neuron_data(dff, start_edge, labels)
    return segments, labels, neuron_pos_filtered, dff, F0_dynamic

# %% ç‰¹æ®Šå‡½æ•°ï¼ˆå’Œåˆºæ¿€ç±»å‹ç­‰ç›¸å…³ï¼‰
def reclassify(stimulus_data):
    '''
    åˆºæ¿€é‡æ–°åˆ†ç±»å‡½æ•°ï¼šå°†å­—ç¬¦ä¸²æ ‡ç­¾è½¬æ¢ä¸ºæ•°å€¼ç±»åˆ«ã€‚
    IC2->1, IC4->2, LC2->3, LC4->4
    '''
    mapping = {
        'IC2': 1,  # ç±»åˆ« 1
        'IC4': 2,  # ç±»åˆ« 2
        'LC2': 3,  # ç±»åˆ« 3
        'LC4': 4,  # ç±»åˆ« 4
    }
    
    new_labels = []
    for label in stimulus_data:
        new_labels.append(mapping.get(label, 0))
    return np.array(new_labels)

# %% å¯è§†åŒ–ç›¸å…³å‡½æ•°å®šä¹‰
def _rr_distribution_plot(neuron_pos, neuron_pos_rr_exc, neuron_pos_rr_inh, plot_dir, suffix, cfg=cfg):
    """RR neuron distribution plot (çº¢=å…´å¥‹æ€§ï¼Œè“=æŠ‘åˆ¶æ€§)"""
    from tifffile import imread # ç¡®ä¿ imread åœ¨è¿™é‡Œè¢«å¼•å…¥

    fig, ax = plt.subplots(figsize=(8.0, 6.2))
    
    # ------------------- æ–‡ä»¶è¯»å–æ£€æŸ¥é€»è¾‘ -------------------
    try:
        # å°è¯•è¯»å– TIF æ–‡ä»¶
        tif_path = os.path.join(cfg.data_path, "whole_brain_3d.tif")
        brain_img = imread(tif_path)
        
        # æˆåŠŸè¯»å–åï¼Œè¿›è¡Œå¤„ç†å’Œç»˜åˆ¶
        mid_slice = brain_img[brain_img.shape[0] // 2, :, :].astype(float)
        mid_slice = mid_slice / np.nanmax(mid_slice)
        ax.imshow(mid_slice, cmap="Greys", alpha=0.35)
        print(f"èƒŒæ™¯è„‘å›¾æ–‡ä»¶ {tif_path} è¯»å–æˆåŠŸå¹¶å·²ç»˜åˆ¶ã€‚")
        
        # å¦‚æœèƒŒæ™¯å›¾åŠ è½½æˆåŠŸï¼Œä½¿ç”¨å…¶å°ºå¯¸æ¥ç¡®å®šåæ ‡è½´èŒƒå›´
        y_max = mid_slice.shape[0] 
        x_max = mid_slice.shape[1]

    except FileNotFoundError:
        print(f"è­¦å‘Š: è„‘å›¾æ–‡ä»¶ {cfg.data_path}/whole_brain_3d.tif æœªæ‰¾åˆ°ï¼Œè·³è¿‡èƒŒæ™¯å›¾ç»˜åˆ¶ã€‚")
        # å¦‚æœæ–‡ä»¶æœªæ‰¾åˆ°ï¼Œæ ¹æ®ç¥ç»å…ƒæ•°æ®ä¼°è®¡åæ ‡è½´èŒƒå›´
        y_max = np.nanmax(neuron_pos[0, :]) if neuron_pos.size > 0 else 3000
        x_max = np.nanmax(neuron_pos[1, :]) if neuron_pos.size > 0 else 3000
        # å¢åŠ ä¸€ç‚¹ç¼“å†²
        y_max += 10
        x_max += 10
        
    except Exception as e:
        print(f"è­¦å‘Š: è¯»å–è„‘å›¾æ–‡ä»¶ {cfg.data_path}/whole_brain_3d.tif å¤±è´¥ï¼Œè·³è¿‡èƒŒæ™¯å›¾ç»˜åˆ¶ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        # å¦‚æœè¯»å–å¤±è´¥ï¼Œæ ¹æ®ç¥ç»å…ƒæ•°æ®ä¼°è®¡åæ ‡è½´èŒƒå›´
        y_max = np.nanmax(neuron_pos[0, :]) if neuron_pos.size > 0 else 3000
        x_max = np.nanmax(neuron_pos[1, :]) if neuron_pos.size > 0 else 3000
        y_max += 10
        x_max += 10
    # ------------------- æ–‡ä»¶è¯»å–æ£€æŸ¥é€»è¾‘ç»“æŸ -------------------


    # ç»˜åˆ¶å…¨éƒ¨ç¥ç»å…ƒ
    sns.scatterplot(
        x=neuron_pos[1, :],
        y=neuron_pos[0, :],
        s=18,
        color="#9fb3c8",
        alpha=0.35,
        edgecolor="none",
        ax=ax,
        label="All neurons",
    )
    # ç»˜åˆ¶å…´å¥‹æ€§ RR (çº¢)
    if neuron_pos_rr_exc.size > 0:
        n_exc = neuron_pos_rr_exc.shape[1]
        print(f"å‡†å¤‡ç»˜åˆ¶ {n_exc} ä¸ªå…´å¥‹æ€§ RR ç¥ç»å…ƒ")
        # æ£€æŸ¥åæ ‡èŒƒå›´
        x_exc = neuron_pos_rr_exc[1, :]
        y_exc = neuron_pos_rr_exc[0, :]
        print(f"  å…´å¥‹æ€§ X èŒƒå›´: [{np.min(x_exc):.1f}, {np.max(x_exc):.1f}], Y èŒƒå›´: [{np.min(y_exc):.1f}, {np.max(y_exc):.1f}]")
        sns.scatterplot(
            x=x_exc,
            y=y_exc,
            s=42,
            color="#E74C3C",
            edgecolor="white",
            linewidth=0.5,
            ax=ax,
            label=f"Excitatory RR ({n_exc})",
        )
    else:
        print("è­¦å‘Š: æ²¡æœ‰å…´å¥‹æ€§ RR ç¥ç»å…ƒéœ€è¦ç»˜åˆ¶")
    
    # ç»˜åˆ¶æŠ‘åˆ¶æ€§/æ··åˆ RR (è“)
    if neuron_pos_rr_inh.size > 0:
        n_inh = neuron_pos_rr_inh.shape[1]
        print(f"å‡†å¤‡ç»˜åˆ¶ {n_inh} ä¸ªæŠ‘åˆ¶æ€§ RR ç¥ç»å…ƒ")
        # æ£€æŸ¥åæ ‡èŒƒå›´
        x_inh = neuron_pos_rr_inh[1, :]
        y_inh = neuron_pos_rr_inh[0, :]
        print(f"  æŠ‘åˆ¶æ€§ X èŒƒå›´: [{np.min(x_inh):.1f}, {np.max(x_inh):.1f}], Y èŒƒå›´: [{np.min(y_inh):.1f}, {np.max(y_inh):.1f}]")
        sns.scatterplot(
            x=x_inh,
            y=y_inh,
            s=42,
            color="#2E86DE",
            edgecolor="white",
            linewidth=0.5,
            ax=ax,
            label=f"Inhibitory RR ({n_inh})",
        )
    else:
        print("è­¦å‘Š: æ²¡æœ‰æŠ‘åˆ¶æ€§ RR ç¥ç»å…ƒéœ€è¦ç»˜åˆ¶")

    # ------------------- çºµè½´åè½¬é€»è¾‘ -------------------
    # è®¾ç½® X è½´å’Œ Y è½´çš„èŒƒå›´
    ax.set_xlim(0, x_max)
    ax.set_ylim(0, y_max) # åˆå§‹è®¾ç½®ä¸ºæ­£å‘ï¼Œä¸‹ä¸€æ­¥åè½¬

    # **å…³é”®æ­¥éª¤ï¼šåè½¬ Y è½´**
    # è¿™å°†ä½¿ Y è½´ä»ä¸Šåˆ°ä¸‹ï¼ˆä¾‹å¦‚ 3000 åˆ° 0ï¼‰æ˜¾ç¤ºï¼Œä¸å›¾åƒåæ ‡ç³»ä¸€è‡´
    ax.invert_yaxis()
    # ------------------- çºµè½´åè½¬é€»è¾‘ç»“æŸ -------------------
    
    
    ax.set_title('RR neuron spatial distribution', fontsize=13)
    ax.set_xlabel('X (pixels)', fontsize=11)
    ax.set_ylabel('Y (pixels)', fontsize=11)
    ax.legend(frameon=False, fontsize=9, loc='upper right')
    ax.set_aspect('equal')
    sns.despine(ax=ax)
    fig.tight_layout()
    
    save_path = os.path.join(plot_dir, f"rr_distribution_{suffix}.png")
    fig.savefig(save_path, dpi=300)
    print(f"å·²ä¿å­˜ RR åˆ†å¸ƒå›¾: {save_path}")
    
    plt.close(fig)

    return True

# =================å¯è§†åŒ–RRç¥ç»å…ƒå“åº” (ä¿æŒä¸å˜) =====================
def _plot_rr_responses(segments, labels, plot_dir, suffix, neuron_indices=None, n=None, cfg=cfg):
    """RR neuron response plotï¼Œæ ‡é¢˜å±•ç¤ºåŸç¥ç»å…ƒç´¢å¼•"""
    if segments.size == 0 or segments.shape[1] == 0:
        return False
    if neuron_indices is None or len(neuron_indices) == 0:
        neuron_indices = np.arange(segments.shape[1])
    else:
        neuron_indices = np.array(neuron_indices)

    total_neurons = segments.shape[1]
    if n is None or n >= total_neurons:
        sample_indices = np.arange(total_neurons)
    else:
        sample_indices = np.random.choice(np.arange(total_neurons), size=n, replace=False)
    n_samples = len(sample_indices)
    time_axis = np.arange(segments.shape[2])
    class_ids = sorted(np.unique(labels))
    palette = sns.color_palette('tab10', n_colors=len(class_ids))
    color_map = {cls: palette[i] for i, cls in enumerate(class_ids)}

    n_cols = 4
    n_rows = int(np.ceil(n_samples / n_cols))
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4.0 * n_cols, 2.6 * n_rows), sharex=True, sharey=True)
    axes = np.atleast_1d(axes).ravel()

    for ax, neuron_idx in zip(axes, sample_indices):
        for cls in class_ids:
            traces = segments[labels == cls, neuron_idx, :]
            if traces.size == 0:
                continue
            mean_trace = np.mean(traces, axis=0)
            sem_trace = stats.sem(traces, axis=0, nan_policy='omit')
            ax.fill_between(time_axis, mean_trace - sem_trace, mean_trace + sem_trace, color=color_map[cls], alpha=0.18)
            ax.plot(time_axis, mean_trace, color=color_map[cls], linewidth=1.6, label=f'Class {int(cls)}')
        ax.axvline(x=cfg.exp_info["t_stimulus"], color="#aa3a3a", linestyle="--", linewidth=1.0)
        global_idx = neuron_indices[neuron_idx] if neuron_idx < len(neuron_indices) else neuron_idx
        ax.set_title(f'Neuron {int(global_idx)}', fontsize=10)
        ax.set_ylim(-0.3, 1.3)

    for ax in axes[len(sample_indices):]:
        ax.axis('off')

    handles, labels_legend = axes[0].get_legend_handles_labels()
    # è¿‡æ»¤æ‰ Class 0 çš„å›¾ä¾‹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œå› ä¸ºæˆ‘ä»¬åªç­›é€‰äº† label > 0 çš„ class_idsï¼‰
    filtered_handles_labels = [(h, l) for h, l in zip(handles, labels_legend) if l != 'Class 0']
    handles = [item[0] for item in filtered_handles_labels]
    labels_legend = [item[1] for item in filtered_handles_labels]

    if handles:
        fig.legend(handles, labels_legend, frameon=False, loc='upper center', ncol=len(handles))
    for ax in axes[:len(sample_indices)]:
        sns.despine(ax=ax)
        ax.tick_params(labelsize=8)

    fig.text(0.5, 0.02, 'Time (frames)', ha='center', fontsize=11)
    fig.text(0.02, 0.5, 'dF/F', va='center', rotation='vertical', fontsize=11)
    fig.tight_layout(rect=[0.02, 0.04, 0.98, 0.95])
    
    save_path = os.path.join(plot_dir, f"rr_responses_{suffix}.png")
    fig.savefig(save_path, dpi=300)
    print(f"å·²ä¿å­˜ RR å“åº”å›¾: {save_path}")
    
    plt.close(fig)

    return True

# %% =============  ä¸»ç¨‹åºé€»è¾‘ (ä¿®æ”¹ä¸ºè°ƒç”¨ rr_selection_by_class) =============================
if __name__ == "__main__":
    print("å¼€å§‹è¿è¡Œä¸»ç¨‹åº")

    plot_dir = os.path.join(cfg.data_path, "plot")
    if not os.path.exists(plot_dir):
        os.makedirs(plot_dir)
        print(f"å·²åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½•: {plot_dir}")

    # å®šä¹‰ç¼“å­˜æ–‡ä»¶è·¯å¾„
    cache_file = os.path.join(cfg.data_path, "preprocessed_data_cache.npz") 
    print(f"é¢„å¤„ç†æ•°æ®ç¼“å­˜æ–‡ä»¶è·¯å¾„: {cache_file}")

    # 1. å°è¯•åŠ è½½ç¼“å­˜æ•°æ®
    segments, labels, neuron_pos_filtered = None, None, None
    load_from_cache_successful = False
    
    if os.path.exists(cache_file):
        segments_cached, labels_cached, neuron_pos_filtered_cached = load_preprocessed_data_npz(cache_file)
        if segments_cached is not None:
              segments = segments_cached
              labels = labels_cached
              neuron_pos_filtered = neuron_pos_filtered_cached
              load_from_cache_successful = True

    # 2. å¦‚æœç¼“å­˜åŠ è½½å¤±è´¥ï¼Œæ‰§è¡Œå®Œæ•´çš„åŠ è½½å’Œé¢„å¤„ç†æµç¨‹
    if not load_from_cache_successful:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆç¼“å­˜æˆ–ç¼“å­˜åŠ è½½å¤±è´¥ï¼Œæ‰§è¡Œå®Œæ•´çš„åŠ è½½å’Œé¢„å¤„ç†æµç¨‹...")
        
        # 2a. åŠ è½½åŸå§‹æ•°æ® (.mat, .txt, .csv)
        neuron_data_orig, neuron_pos_orig, start_edges, stimulus_data = load_data()
        
        # 2b. æ‰§è¡Œæ˜‚è´µçš„é¢„å¤„ç†å’Œåˆ†å‰²æ­¥éª¤
        segments, labels, neuron_pos_filtered, dff, F0_dynamic = filter_and_segment_data(
            neuron_data_orig, neuron_pos_orig, start_edges, stimulus_data, cfg
        )
        
        # ==================== éªŒè¯ä»£ç  ====================
        print("="*70)
        print("ğŸ” DEBUG CHECKPOINT: Basic Environment Info")
        import sys
        print("Python version:", sys.version)
        import numpy as np
        print("NumPy version:", np.__version__)
        import scipy
        print("SciPy version:", scipy.__version__)
        import h5py
        print("h5py version:", h5py.__version__)
        print("="*70)

        # ==================== Step 1: åŸå§‹ç¥ç»æ•°æ® ====================
        print("\nğŸ§  Step 1: Raw neuron_data stats BEFORE filtering")
        print("neuron_data shape:", neuron_data_orig.shape)
        print("neuron_data [min,max,mean,std]:",
              np.min(neuron_data_orig), np.max(neuron_data_orig),
              np.mean(neuron_data_orig), np.std(neuron_data_orig))

        # æ£€æŸ¥ <=0 çš„åˆ—æ•°é‡ï¼ˆéå¸¸å…³é”®ï¼‰
        neg_cols = np.sum(np.any(neuron_data_orig <= 0, axis=0))
        print("â— Number of columns containing <= 0 values:", neg_cols)

        # ==================== Step 2: dF/F ç»“æœæ£€æŸ¥ ====================
        print("\nğŸ“ˆ Step 2: dF/F stats (after preprocessing)")
        print("dff shape:", dff.shape)
        print("dff [min,max,mean,std]:",
              np.min(dff), np.max(dff),
              np.mean(dff), np.std(dff))

        # æ‰“å°æ¯ 3000 ä¸ªç¥ç»å…ƒçš„ F0 baselineï¼ˆæŠ½æ ·æ£€æŸ¥å·®å¼‚ï¼‰
        if F0_dynamic is not None:
            print("\nğŸ¯ Percentile baseline (F0_dynamic) sample:")
            print("F0_dynamic sample (first 10 values of neuron 0):", F0_dynamic[:10, 0])
        else:
            print("\nğŸ¯ Percentile baseline (F0_dynamic): Not computed (preprocessing disabled)")

        # ==================== Step 3: trigger slicing ====================
        print("\nâ± Step 3: Trigger start_edges")
        print("start_edges length:", len(start_edges))
        print("start_edges first 30:", start_edges[:30])

        # ==================== Step 4: segments consistency ====================
        print("\nğŸª“ Step 4: Segments stats")
        print("segments shape:", segments.shape)
        print("segments [min,max,mean,std]:",
              np.min(segments), np.max(segments),
              np.mean(segments), np.std(segments))

        # ==================== Step 5: labels consistency ====================
        print("\nğŸ· Step 5: Label stats")
        print("labels unique:", np.unique(labels))
        print("labels count:", {l: np.sum(labels == l) for l in np.unique(labels)})

        print("="*70)
        # ==================== éªŒè¯ä»£ç ç»“æŸ ====================
        
        # 2c. ä¿å­˜ç¼“å­˜
        save_preprocessed_data_npz(segments, labels, neuron_pos_filtered, cache_file)
    else:
        print("ç¼“å­˜åŠ è½½æˆåŠŸï¼Œè·³è¿‡åŸå§‹æ•°æ®åŠ è½½å’Œé¢„å¤„ç†æ­¥éª¤ã€‚")


    # 3. RR ç¥ç»å…ƒç­›é€‰ (ä½¿ç”¨åˆ†ç±»åˆ«ç­›é€‰å¹¶å–å¹¶é›†çš„æ–°é€»è¾‘)
    
    rr_enhanced_neurons, rr_inhibitory_neurons = rr_selection_by_class(segments, np.array(labels))
    rr_enhanced_neurons = np.array(sorted(set(rr_enhanced_neurons)), dtype=int)
    rr_inhibitory_neurons = np.array(sorted(set(rr_inhibitory_neurons)), dtype=int)
    
    # æå–å…´å¥‹æ€§ RR ç¥ç»å…ƒçš„æ•°æ®
    enhanced_segments = segments[:, rr_enhanced_neurons, :] if rr_enhanced_neurons.size > 0 else np.empty((segments.shape[0], 0, segments.shape[2]))
    enhanced_neuron_pos_rr = neuron_pos_filtered[:, rr_enhanced_neurons] if rr_enhanced_neurons.size > 0 else np.empty((2, 0))
    print(f"\nå…´å¥‹æ€§ RR ç¥ç»å…ƒ: {len(rr_enhanced_neurons)} ä¸ª, ä½ç½®æ•°æ®å½¢çŠ¶: {enhanced_neuron_pos_rr.shape}")

    # æå–æŠ‘åˆ¶æ€§ RR ç¥ç»å…ƒçš„æ•°æ®
    inhibitory_segments = segments[:, rr_inhibitory_neurons, :] if rr_inhibitory_neurons.size > 0 else np.empty((segments.shape[0], 0, segments.shape[2]))
    inhibitory_neuron_pos_rr = neuron_pos_filtered[:, rr_inhibitory_neurons] if rr_inhibitory_neurons.size > 0 else np.empty((2, 0))
    print(f"æŠ‘åˆ¶æ€§ RR ç¥ç»å…ƒ: {len(rr_inhibitory_neurons)} ä¸ª, ä½ç½®æ•°æ®å½¢çŠ¶: {inhibitory_neuron_pos_rr.shape}")

    # %% å¯è§†åŒ–RRç¥ç»å…ƒåˆ†å¸ƒ (å…¨éƒ¨RRï¼Œçº¢=å…´å¥‹æ€§ï¼Œè“=æŠ‘åˆ¶æ€§)
    _rr_distribution_plot(
        neuron_pos_filtered,
        enhanced_neuron_pos_rr,
        inhibitory_neuron_pos_rr,
        plot_dir,
        "AllRR_ByClass"
    )
    # %% å¯è§†åŒ–RRç¥ç»å…ƒå“åº” (å…´å¥‹æ€§)
    #   _plot_rr_responses(enhanced_segments, labels, plot_dir, "Excitatory_ByClass", neuron_indices=rr_enhanced_neurons, n=None)

    # %% å¯è§†åŒ–RRç¥ç»å…ƒå“åº” (æŠ‘åˆ¶æ€§)
    #_plot_rr_responses(inhibitory_segments, labels, plot_dir, "Inhibitory_ByClass", neuron_indices=rr_inhibitory_neurons, n=None)

    print(f"å…´å¥‹æ€§ RR ç¥ç»å…ƒç´¢å¼•æ€»æ•° {len(rr_enhanced_neurons)}: {rr_enhanced_neurons.tolist()}")
    print(f"æŠ‘åˆ¶æ€§ RR ç¥ç»å…ƒç´¢å¼•æ€»æ•° {len(rr_inhibitory_neurons)}: {rr_inhibitory_neurons.tolist()}")

    # å°†ç´¢å¼•å†™å…¥ CSV
    rr_index_path = os.path.join(cfg.data_path, "rr_neuron_indices.csv")
    rr_index_df = pd.DataFrame({
        "neuron_index": np.concatenate([rr_enhanced_neurons, rr_inhibitory_neurons]),
        "category": (["exc"] * len(rr_enhanced_neurons)) + (["inh"] * len(rr_inhibitory_neurons))
    })
    rr_index_df.to_csv(rr_index_path, index=False, encoding="utf-8-sig")
    print(f"RR ç¥ç»å…ƒç´¢å¼•å·²ä¿å­˜åˆ°: {rr_index_path}")